use random seed: 5230
=== Training classifier for source domain ===
>>> Source Encoder <<<
LeNetEncoder(
  (encoder): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU()
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): Dropout2d(p=0.5, inplace=False)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): ReLU()
  )
  (fc1): Linear(in_features=800, out_features=500, bias=True)
)
>>> Source Classifier <<<
LeNetClassifier(
  (fc2): Linear(in_features=500, out_features=10, bias=True)
)
Epoch [1/3] Step [20/1200]: loss=2.294461727142334
Epoch [1/3] Step [40/1200]: loss=2.2725892066955566
Epoch [1/3] Step [60/1200]: loss=2.239591598510742
Epoch [1/3] Step [80/1200]: loss=2.1777989864349365
Epoch [1/3] Step [100/1200]: loss=2.0563302040100098
Epoch [1/3] Step [120/1200]: loss=1.8896284103393555
Epoch [1/3] Step [140/1200]: loss=1.7279443740844727
Epoch [1/3] Step [160/1200]: loss=1.5886836051940918
Epoch [1/3] Step [180/1200]: loss=1.450800895690918
Epoch [1/3] Step [200/1200]: loss=1.0362577438354492
Epoch [1/3] Step [220/1200]: loss=0.8712989687919617
Epoch [1/3] Step [240/1200]: loss=0.8712397813796997
Epoch [1/3] Step [260/1200]: loss=0.9322513341903687
Epoch [1/3] Step [280/1200]: loss=0.9654003381729126
Epoch [1/3] Step [300/1200]: loss=0.7694005370140076
Epoch [1/3] Step [320/1200]: loss=0.7409395575523376
Epoch [1/3] Step [340/1200]: loss=0.7356046438217163
Epoch [1/3] Step [360/1200]: loss=0.5753569602966309
Epoch [1/3] Step [380/1200]: loss=0.6408174633979797
Epoch [1/3] Step [400/1200]: loss=0.554402768611908
Epoch [1/3] Step [420/1200]: loss=0.5834531188011169
Epoch [1/3] Step [440/1200]: loss=0.47278496623039246
Epoch [1/3] Step [460/1200]: loss=0.3553670048713684
Epoch [1/3] Step [480/1200]: loss=0.5462448000907898
Epoch [1/3] Step [500/1200]: loss=0.4970620274543762
Epoch [1/3] Step [520/1200]: loss=0.3705701529979706
Epoch [1/3] Step [540/1200]: loss=0.6516837477684021
Epoch [1/3] Step [560/1200]: loss=0.28786471486091614
Epoch [1/3] Step [580/1200]: loss=0.29553133249282837
Epoch [1/3] Step [600/1200]: loss=0.4294043779373169
Epoch [1/3] Step [620/1200]: loss=0.3878857493400574
Epoch [1/3] Step [640/1200]: loss=0.42820098996162415
Epoch [1/3] Step [660/1200]: loss=0.41891011595726013
Epoch [1/3] Step [680/1200]: loss=0.4313325583934784
Epoch [1/3] Step [700/1200]: loss=0.27607330679893494
Epoch [1/3] Step [720/1200]: loss=0.19726526737213135
Epoch [1/3] Step [740/1200]: loss=0.31561553478240967
Epoch [1/3] Step [760/1200]: loss=0.451384037733078
Epoch [1/3] Step [780/1200]: loss=0.23034274578094482
Epoch [1/3] Step [800/1200]: loss=0.3533429205417633
Epoch [1/3] Step [820/1200]: loss=0.3740636110305786
Epoch [1/3] Step [840/1200]: loss=0.32828426361083984
Epoch [1/3] Step [860/1200]: loss=0.26086199283599854
Epoch [1/3] Step [880/1200]: loss=0.4798576831817627
Epoch [1/3] Step [900/1200]: loss=0.5101621150970459
Epoch [1/3] Step [920/1200]: loss=0.29319021105766296
Epoch [1/3] Step [940/1200]: loss=0.2458626925945282
Epoch [1/3] Step [960/1200]: loss=0.424869567155838
Epoch [1/3] Step [980/1200]: loss=0.5030420422554016
Epoch [1/3] Step [1000/1200]: loss=0.5022820830345154
Epoch [1/3] Step [1020/1200]: loss=0.24785667657852173
Epoch [1/3] Step [1040/1200]: loss=0.23359909653663635
Epoch [1/3] Step [1060/1200]: loss=0.26503676176071167
Epoch [1/3] Step [1080/1200]: loss=0.30352696776390076
Epoch [1/3] Step [1100/1200]: loss=0.5749082565307617
Epoch [1/3] Step [1120/1200]: loss=0.4785197377204895
Epoch [1/3] Step [1140/1200]: loss=0.1889018416404724
Epoch [1/3] Step [1160/1200]: loss=0.5859458446502686
Epoch [1/3] Step [1180/1200]: loss=0.10580632090568542
Epoch [1/3] Step [1200/1200]: loss=0.45536288619041443
Epoch [2/3] Step [20/1200]: loss=0.20114204287528992
Epoch [2/3] Step [40/1200]: loss=0.26827138662338257
Epoch [2/3] Step [60/1200]: loss=0.2385559231042862
Epoch [2/3] Step [80/1200]: loss=0.18846125900745392
Epoch [2/3] Step [100/1200]: loss=0.08904243260622025
Epoch [2/3] Step [120/1200]: loss=0.30649420619010925
Epoch [2/3] Step [140/1200]: loss=0.5009858012199402
Epoch [2/3] Step [160/1200]: loss=0.4084640145301819
Epoch [2/3] Step [180/1200]: loss=0.07760167866945267
Epoch [2/3] Step [200/1200]: loss=0.27218952775001526
Epoch [2/3] Step [220/1200]: loss=0.37289467453956604
Epoch [2/3] Step [240/1200]: loss=0.20022135972976685
Epoch [2/3] Step [260/1200]: loss=0.18930985033512115
Epoch [2/3] Step [280/1200]: loss=0.09545884281396866
Epoch [2/3] Step [300/1200]: loss=0.18703821301460266
Epoch [2/3] Step [320/1200]: loss=0.6000007390975952
Epoch [2/3] Step [340/1200]: loss=0.07484021037817001
Epoch [2/3] Step [360/1200]: loss=0.08816348761320114
Epoch [2/3] Step [380/1200]: loss=0.27519336342811584
Epoch [2/3] Step [400/1200]: loss=0.3840655982494354
Epoch [2/3] Step [420/1200]: loss=0.41268840432167053
Epoch [2/3] Step [440/1200]: loss=0.24284987151622772
Epoch [2/3] Step [460/1200]: loss=0.19103404879570007
Epoch [2/3] Step [480/1200]: loss=0.09441104531288147
Epoch [2/3] Step [500/1200]: loss=0.18820898234844208
Epoch [2/3] Step [520/1200]: loss=0.26827237010002136
Epoch [2/3] Step [540/1200]: loss=0.2845015227794647
Epoch [2/3] Step [560/1200]: loss=0.18500660359859467
Epoch [2/3] Step [580/1200]: loss=0.2051776498556137
Epoch [2/3] Step [600/1200]: loss=0.3115292489528656
Epoch [2/3] Step [620/1200]: loss=0.21021240949630737
Epoch [2/3] Step [640/1200]: loss=0.17699302732944489
Epoch [2/3] Step [660/1200]: loss=0.057930491864681244
Epoch [2/3] Step [680/1200]: loss=0.09322129189968109
Epoch [2/3] Step [700/1200]: loss=0.24943295121192932
Epoch [2/3] Step [720/1200]: loss=0.2158079743385315
Epoch [2/3] Step [740/1200]: loss=0.13559424877166748
Epoch [2/3] Step [760/1200]: loss=0.17064641416072845
Epoch [2/3] Step [780/1200]: loss=0.2849321663379669
Epoch [2/3] Step [800/1200]: loss=0.17905841767787933
Epoch [2/3] Step [820/1200]: loss=0.1486922800540924
Epoch [2/3] Step [840/1200]: loss=0.09536764770746231
Epoch [2/3] Step [860/1200]: loss=0.1736956238746643
Epoch [2/3] Step [880/1200]: loss=0.1387118101119995
Epoch [2/3] Step [900/1200]: loss=0.1973041296005249
Epoch [2/3] Step [920/1200]: loss=0.18128694593906403
Epoch [2/3] Step [940/1200]: loss=0.07784512639045715
Epoch [2/3] Step [960/1200]: loss=0.179641455411911
Epoch [2/3] Step [980/1200]: loss=0.33482906222343445
Epoch [2/3] Step [1000/1200]: loss=0.18319672346115112
Epoch [2/3] Step [1020/1200]: loss=0.1890604943037033
Epoch [2/3] Step [1040/1200]: loss=0.14596493542194366
Epoch [2/3] Step [1060/1200]: loss=0.16082912683486938
Epoch [2/3] Step [1080/1200]: loss=0.23260612785816193
Epoch [2/3] Step [1100/1200]: loss=0.08456750959157944
Epoch [2/3] Step [1120/1200]: loss=0.08096623420715332
Epoch [2/3] Step [1140/1200]: loss=0.10805074870586395
Epoch [2/3] Step [1160/1200]: loss=0.16748766601085663
Epoch [2/3] Step [1180/1200]: loss=0.2481634020805359
Epoch [2/3] Step [1200/1200]: loss=0.08108773827552795
Epoch [3/3] Step [20/1200]: loss=0.05674348399043083
Epoch [3/3] Step [40/1200]: loss=0.2581954896450043
Epoch [3/3] Step [60/1200]: loss=0.04603404179215431
Epoch [3/3] Step [80/1200]: loss=0.09090490639209747
Epoch [3/3] Step [100/1200]: loss=0.1641881763935089
Epoch [3/3] Step [120/1200]: loss=0.41807764768600464
Epoch [3/3] Step [140/1200]: loss=0.1271085888147354
Epoch [3/3] Step [160/1200]: loss=0.15348386764526367
Epoch [3/3] Step [180/1200]: loss=0.036510344594717026
Epoch [3/3] Step [200/1200]: loss=0.0569286048412323
Epoch [3/3] Step [220/1200]: loss=0.12087924778461456
Epoch [3/3] Step [240/1200]: loss=0.20922334492206573
Epoch [3/3] Step [260/1200]: loss=0.10251648724079132
Epoch [3/3] Step [280/1200]: loss=0.0487813800573349
Epoch [3/3] Step [300/1200]: loss=0.2385476529598236
Epoch [3/3] Step [320/1200]: loss=0.06082136556506157
Epoch [3/3] Step [340/1200]: loss=0.31258419156074524
Epoch [3/3] Step [360/1200]: loss=0.3447326421737671
Epoch [3/3] Step [380/1200]: loss=0.11745244264602661
Epoch [3/3] Step [400/1200]: loss=0.14306148886680603
Epoch [3/3] Step [420/1200]: loss=0.061154428869485855
Epoch [3/3] Step [440/1200]: loss=0.17852790653705597
Epoch [3/3] Step [460/1200]: loss=0.038244958966970444
Epoch [3/3] Step [480/1200]: loss=0.052199870347976685
Epoch [3/3] Step [500/1200]: loss=0.06687992811203003
Epoch [3/3] Step [520/1200]: loss=0.17335273325443268
Epoch [3/3] Step [540/1200]: loss=0.1824856549501419
Epoch [3/3] Step [560/1200]: loss=0.12195194512605667
Epoch [3/3] Step [580/1200]: loss=0.14171259105205536
Epoch [3/3] Step [600/1200]: loss=0.12618739902973175
Epoch [3/3] Step [620/1200]: loss=0.12759670615196228
Epoch [3/3] Step [640/1200]: loss=0.09589505940675735
Epoch [3/3] Step [660/1200]: loss=0.11361508071422577
Epoch [3/3] Step [680/1200]: loss=0.23565573990345
Epoch [3/3] Step [700/1200]: loss=0.0512596033513546
Epoch [3/3] Step [720/1200]: loss=0.26571911573410034
Epoch [3/3] Step [740/1200]: loss=0.08480232208967209
Epoch [3/3] Step [760/1200]: loss=0.021435081958770752
Epoch [3/3] Step [780/1200]: loss=0.13183319568634033
Epoch [3/3] Step [800/1200]: loss=0.11193820834159851
Epoch [3/3] Step [820/1200]: loss=0.31476306915283203
Epoch [3/3] Step [840/1200]: loss=0.14143286645412445
Epoch [3/3] Step [860/1200]: loss=0.131785586476326
Epoch [3/3] Step [880/1200]: loss=0.3001886010169983
Epoch [3/3] Step [900/1200]: loss=0.14048488438129425
Epoch [3/3] Step [920/1200]: loss=0.08409085124731064
Epoch [3/3] Step [940/1200]: loss=0.06960500031709671
Epoch [3/3] Step [960/1200]: loss=0.31416434049606323
Epoch [3/3] Step [980/1200]: loss=0.13561177253723145
Epoch [3/3] Step [1000/1200]: loss=0.22504740953445435
Epoch [3/3] Step [1020/1200]: loss=0.06949662417173386
Epoch [3/3] Step [1040/1200]: loss=0.330581396818161
Epoch [3/3] Step [1060/1200]: loss=0.1634358912706375
Epoch [3/3] Step [1080/1200]: loss=0.15888118743896484
Epoch [3/3] Step [1100/1200]: loss=0.06453564763069153
Epoch [3/3] Step [1120/1200]: loss=0.47613564133644104
Epoch [3/3] Step [1140/1200]: loss=0.07727933675050735
Epoch [3/3] Step [1160/1200]: loss=0.02456865832209587
Epoch [3/3] Step [1180/1200]: loss=0.1387280523777008
Epoch [3/3] Step [1200/1200]: loss=0.17695026099681854
save pretrained model to: snapshots\ADDA-source-encoder-final.pt
save pretrained model to: snapshots\ADDA-source-classifier-final.pt
=== Evaluating classifier for source domain ===
Avg Loss = 0.06913270056247711, Avg Accuracy = 97.730000%
=== Training encoder for target domain ===
>>> Target Encoder <<<
LeNetEncoder(
  (encoder): Sequential(
    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU()
    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (4): Dropout2d(p=0.5, inplace=False)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): ReLU()
  )
  (fc1): Linear(in_features=800, out_features=500, bias=True)
)
>>> Critic <<<
Discriminator(
  (layer): Sequential(
    (0): Linear(in_features=500, out_features=500, bias=True)
    (1): ReLU()
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): ReLU()
    (4): Linear(in_features=500, out_features=2, bias=True)
    (5): LogSoftmax(dim=1)
  )
)
Epoch [1/20] Step [100/149]:d_loss=0.66668 g_loss=0.71342 acc=0.66000
Epoch [2/20] Step [100/149]:d_loss=0.64705 g_loss=0.75366 acc=0.66000
Epoch [3/20] Step [100/149]:d_loss=0.65005 g_loss=0.80639 acc=0.60000
Epoch [4/20] Step [100/149]:d_loss=0.63605 g_loss=0.82513 acc=0.71000
Epoch [5/20] Step [100/149]:d_loss=0.64868 g_loss=0.86041 acc=0.67000
Epoch [6/20] Step [100/149]:d_loss=0.63325 g_loss=0.82078 acc=0.60000
Epoch [7/20] Step [100/149]:d_loss=0.65402 g_loss=0.88438 acc=0.55000
Epoch [8/20] Step [100/149]:d_loss=0.63759 g_loss=0.80922 acc=0.67000
Epoch [9/20] Step [100/149]:d_loss=0.61992 g_loss=0.81340 acc=0.67000
Epoch [10/20] Step [100/149]:d_loss=0.64231 g_loss=0.91805 acc=0.67000
Epoch [11/20] Step [100/149]:d_loss=0.64946 g_loss=0.79708 acc=0.64000
Epoch [12/20] Step [100/149]:d_loss=0.68283 g_loss=0.84458 acc=0.51000
Epoch [13/20] Step [100/149]:d_loss=0.65865 g_loss=0.80104 acc=0.60000
Epoch [14/20] Step [100/149]:d_loss=0.64140 g_loss=0.86577 acc=0.61000
Epoch [15/20] Step [100/149]:d_loss=0.63675 g_loss=0.85735 acc=0.64000
Epoch [16/20] Step [100/149]:d_loss=0.65020 g_loss=0.76065 acc=0.67000
Epoch [17/20] Step [100/149]:d_loss=0.58774 g_loss=0.82998 acc=0.69000
Epoch [18/20] Step [100/149]:d_loss=0.66210 g_loss=0.78845 acc=0.58000
Epoch [19/20] Step [100/149]:d_loss=0.64851 g_loss=0.80241 acc=0.66000
Epoch [20/20] Step [100/149]:d_loss=0.63857 g_loss=0.89575 acc=0.61000
=== Evaluating classifier for encoded target domain ===
>>> source only <<<
Avg Loss = 0.36964085698127747, Avg Accuracy = 88.709677%
>>> domain adaption <<<
Avg Loss = 0.15848800539970398, Avg Accuracy = 95.322581%